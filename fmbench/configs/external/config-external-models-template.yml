## External Models Benchmarking Template for Bedrock-only version of FMBench
## This template shows how to benchmark OpenAI, Azure OpenAI, and Google models alongside Bedrock models

general:
  name: bedrock-vs-external-models-benchmark

aws:
  region: {region}
  bucket: {write_bucket}
  s3_and_or_local_file_system: s3

run_steps:
  0_setup.ipynb: yes
  1_generate_data.ipynb: yes
  2_deploy_model.ipynb: yes  # Needed even though deploy is 'no' - this registers endpoints
  3_run_inference.ipynb: yes
  4_get_evaluations.ipynb: yes
  5_model_metric_analysis.ipynb: yes
  6_cleanup.ipynb: no

# Source data files - can use any compatible dataset
source_data_files:
  - hf:THUDM/LongBench/2wikimqa_e/test

# Metrics thresholds for the report
report:
  latency_budget: 5
  cosine_similarity_budget: 0.3
  accuracy_budget: 0.7
  accuracy_error_rate_budget: 0.3
  cost_per_10k_txn_budget: 300
  error_rate_budget: 0.1

# Dataset configuration
datasets:
  min_iters_per_combination: 10
  max_iters_per_combination: 20
  prompt_template_keys:
    - input
    - context
  filters:
    - language: en    
      min_length_in_tokens: 1000
      max_length_in_tokens: 2000
      payload_file: payload_en_1000-2000.jsonl
  metrics:
    dataset_of_interest: en_1000-2000

# Pricing information
pricing: pricing.yml

# Prompt template to use
prompt_template_file: prompt_template_llama3.txt

# Model evaluations
model_evaluations: model_eval_all_info.yml
ground_truth_col_key: answers
question_col_key: input

# Define the inference parameters for each type of endpoint
inference_parameters:
  # Parameters for Bedrock models
  bedrock:
    temperature: 0.1
    max_tokens: 100
    top_p: 0.9
  
  # Parameters for OpenAI models
  openai:
    temperature: 0.1
    max_tokens: 100
    top_p: 0.9
    provider: openai
    pricing:
      input_price_per_1k: 0.01    # $0.01 per 1K input tokens
      output_price_per_1k: 0.03   # $0.03 per 1K output tokens
    api_keys:
      OPENAI_API_KEY: "YOUR_OPENAI_API_KEY" # Replace with your actual API key
  
  # Parameters for Azure OpenAI models
  azure_openai:
    temperature: 0.1
    max_tokens: 100
    top_p: 0.9
    provider: azure
    api_version: "2023-05-15"
    base_url: "https://your-resource-name.openai.azure.com"
    pricing:
      input_price_per_1k: 0.01    # $0.01 per 1K input tokens
      output_price_per_1k: 0.03   # $0.03 per 1K output tokens
    api_keys:
      AZURE_OPENAI_API_KEY: "YOUR_AZURE_API_KEY" # Replace with your actual API key
  
  # Parameters for Google models
  google:
    temperature: 0.1
    max_tokens: 100
    top_p: 0.9
    provider: google
    pricing:
      input_price_per_1k: 0.0005  # $0.0005 per 1K input tokens
      output_price_per_1k: 0.001  # $0.001 per 1K output tokens
    api_keys:
      GOOGLE_API_KEY: "YOUR_GOOGLE_API_KEY" # Replace with your actual API key

# Model configurations
experiments:
  # Bedrock model
  - name: claude-sonnet
    model_id: anthropic.claude-3-sonnet-20240229-v1:0
    model_name: Claude 3 Sonnet
    ep_name: anthropic.claude-3-sonnet-20240229-v1:0
    instance_type: anthropic.claude-3-sonnet-20240229-v1:0
    deploy: no
    instance_count: 1
    inference_script: bedrock_predictor.py
    inference_spec:
      parameter_set: bedrock
    concurrency_levels:
      - 1
      - 2
    payload_files:
      - payload_en_1000-2000.jsonl

  # OpenAI model
  - name: gpt-4o
    model_id: gpt-4o
    model_name: GPT-4o
    ep_name: gpt-4o
    instance_type: gpt-4o  # Used for pricing reference
    deploy: no
    instance_count: 1
    inference_script: litellm_predictor.py
    inference_spec:
      parameter_set: openai
    concurrency_levels:
      - 1
      - 2
    payload_files:
      - payload_en_1000-2000.jsonl

  # Azure OpenAI model
  - name: azure-gpt-4
    model_id: gpt-4
    model_name: Azure GPT-4
    ep_name: gpt-4
    instance_type: azure-gpt-4  # Used for pricing reference
    deploy: no
    instance_count: 1
    inference_script: litellm_predictor.py
    inference_spec:
      parameter_set: azure_openai
    concurrency_levels:
      - 1
      - 2
    payload_files:
      - payload_en_1000-2000.jsonl

  # Google model
  - name: gemini-pro
    model_id: gemini-pro
    model_name: Gemini Pro
    ep_name: gemini-pro
    instance_type: gemini-pro  # Used for pricing reference
    deploy: no
    instance_count: 1
    inference_script: litellm_predictor.py
    inference_spec:
      parameter_set: google
    concurrency_levels:
      - 1
      - 2
    payload_files:
      - payload_en_1000-2000.jsonl